<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>【比赛】CCF - BDCI - 个贷违约预测【排名：13/3246】</title>
    <link href="/2021/12/03/%E3%80%90%E6%AF%94%E8%B5%9B%E3%80%91CCF%20-%20BDCI%20-%20%E4%B8%AA%E8%B4%B7%E8%BF%9D%E7%BA%A6%E9%A2%84%E6%B5%8B/"/>
    <url>/2021/12/03/%E3%80%90%E6%AF%94%E8%B5%9B%E3%80%91CCF%20-%20BDCI%20-%20%E4%B8%AA%E8%B4%B7%E8%BF%9D%E7%BA%A6%E9%A2%84%E6%B5%8B/</url>
    
    <content type="html"><![CDATA[<div class="note note-success">            <p>比赛传送门：<a href="https://www.datafountain.cn/competitions/530/datasets">https://www.datafountain.cn/competitions/530/datasets</a></p>          </div><h2 id="前期分析"><a href="#前期分析" class="headerlink" title="前期分析"></a>前期分析</h2><h3 id="需求分析"><a href="#需求分析" class="headerlink" title="需求分析"></a>需求分析</h3><ul><li><p>人话——两个训练集预测一个测试集的二分类问题，指标为AUC。</p></li><li><p>鬼话——迁移学习，使用网上不知名处搜刮到的信贷数据（75w），以及自己的少量过往数据（仅1.5w)，来辅助预测该银行（委托方）自己的业务数据的违约情况。且所包含特征各不相同，部分同名特征同字段或同编码的含义也不完全相同，重要特征的分布也有极大的不同，这些可恶的数据居然也要用来辅助预测。</p></li></ul><h3 id="文件清单和使用说明"><a href="#文件清单和使用说明" class="headerlink" title="文件清单和使用说明"></a>文件清单和使用说明</h3><p><strong>训练数据</strong>   train_public.csv 个人贷款违约记录数据   train_internet_public.csv 某网络信用贷产品违约记录数据</p><p><strong>测试数据</strong>   test_public.csv 用于测试的数据，获取榜单排名</p><p><strong>训练数据说明</strong></p><ul><li>train_public.csv</li></ul><div class="table-container"><table><thead><tr><th>字段</th><th>字段描述</th></tr></thead><tbody><tr><td>loan_id（主键）</td><td>贷款记录唯一标识</td></tr><tr><td>user_id</td><td>借款人唯一标识</td></tr><tr><td>total_loan</td><td>贷款数额</td></tr><tr><td>year_of_loan</td><td>贷款年份</td></tr><tr><td>interest</td><td>当前贷款利率</td></tr><tr><td>monthly_payment</td><td>分期付款金额</td></tr><tr><td>grade</td><td>贷款级别</td></tr><tr><td>employment_type</td><td>所在公司类型（世界五百强、国有企业、普通企业…）</td></tr><tr><td>industry</td><td>工作领域（传统工业、商业、互联网、金融…）</td></tr><tr><td>work_year</td><td>工作年限</td></tr><tr><td>home_exist</td><td>是否有房</td></tr><tr><td>censor_status</td><td>审核情况</td></tr><tr><td>issue_month</td><td>贷款发放的月份</td></tr><tr><td>use</td><td>贷款用途类别</td></tr><tr><td>post_code</td><td>贷款人申请时邮政编码</td></tr><tr><td>region</td><td>地区编码</td></tr><tr><td>debt_loan_ratio</td><td>债务收入比</td></tr><tr><td>del_in_18month</td><td>借款人过去18个月逾期30天以上的违约事件数</td></tr><tr><td>scoring_low</td><td>借款人在贷款评分中所属的下限范围</td></tr><tr><td>scoring_high</td><td>借款人在贷款评分中所属的上限范围</td></tr><tr><td>pub_dero_bankrup</td><td>公开记录清除的数量</td></tr><tr><td>recircle_bal</td><td>信贷周转余额合计</td></tr><tr><td>recircle_util</td><td>循环额度利用率</td></tr><tr><td>initial_list_status</td><td>贷款的初始列表状态</td></tr><tr><td>earlies_credit_mon</td><td>借款人最早报告的信用额度开立的月份</td></tr><tr><td>title</td><td>借款人提供的贷款名称</td></tr><tr><td>policy_code</td><td>公开可用的策略<em>代码=1新产品不公开可用的策略</em>代码=2</td></tr><tr><td>f系列匿名特征</td><td>匿名特征f0-f4，为一些贷款人行为计数特征的处理</td></tr><tr><td>early_return</td><td>借款人提前还款次数</td></tr><tr><td>early_return_amount</td><td>贷款人提前还款累积金额</td></tr><tr><td>early_return_amount_3mon</td><td>近3个月内提前还款金额</td></tr><tr><td><strong>known_outstanding_loan</strong></td><td>借款人档案中未结信用额度的数量</td></tr><tr><td><strong>known_dero</strong></td><td>贬损公共记录的数量</td></tr><tr><td><strong>app_type</strong></td><td>是否个人申请</td></tr></tbody></table></div><ul><li>train_internet.csv</li></ul><div class="table-container"><table><thead><tr><th>字段</th><th>字段描述</th></tr></thead><tbody><tr><td>loan_id</td><td>网络贷款记录唯一标识</td></tr><tr><td>user_id</td><td>用户唯一标识</td></tr><tr><td>total_loan</td><td>网络贷款金额</td></tr><tr><td>year_of_loan</td><td>网络贷款期限（year）</td></tr><tr><td>interest</td><td>网络贷款利率</td></tr><tr><td>monthly_payment</td><td>分期付款金额</td></tr><tr><td>class</td><td>网络贷款等级</td></tr><tr><td>employment_type</td><td>所在公司类型（世界五百强、国有企业、普通企业…）</td></tr><tr><td>industry</td><td>工作领域（传统工业、商业、互联网、金融…）</td></tr><tr><td>work_year</td><td>就业年限（年）</td></tr><tr><td>house_ownership</td><td>是否有房</td></tr><tr><td>censor_status</td><td>验证状态</td></tr><tr><td>issue_date</td><td>网络贷款发放的月份</td></tr><tr><td>use</td><td>贷款用途</td></tr><tr><td>post_code</td><td>借款人邮政编码的前3位</td></tr><tr><td>region</td><td>地区编码</td></tr><tr><td>debt_loan_ratio</td><td>债务收入比</td></tr><tr><td>del_in_18month</td><td>借款人过去18个月信用档案中逾期60天内的违约事件数</td></tr><tr><td>scoring_low</td><td>借款人在信用评分系统所属的下限范围</td></tr><tr><td>scoring_high</td><td>借款人在信用评分系统所属的上限范围</td></tr><tr><td>pub_dero_bankrup</td><td>公开记录清除的数量</td></tr><tr><td>early_return</td><td>提前还款次数</td></tr><tr><td>early_return_amount</td><td>提前还款累积金额</td></tr><tr><td>early_return_amount_3mon</td><td>近3个月内提前还款金额</td></tr><tr><td>recircle_bal</td><td>信贷周转余额合计</td></tr><tr><td>recircle_util</td><td>循环额度利用率，或借款人使用的相对于所有可用循环信贷的信贷金额</td></tr><tr><td>initial_list_status</td><td>网络贷款的初始列表状态</td></tr><tr><td>earlies_credit_line</td><td>网络贷款信用额度开立的月份</td></tr><tr><td>title</td><td>借款人提供的网络贷款名称</td></tr><tr><td>policy_code</td><td>公开策略=1不公开策略=2</td></tr><tr><td><strong>f系列匿名特征</strong></td><td>匿名特征f0-f5，为一些网络贷款人行为计数特征的处理——<strong>多一个f5</strong></td></tr><tr><td><strong>sub_class</strong></td><td>网络贷款等级之子级</td></tr><tr><td><strong>work_type</strong></td><td>工作类型（公务员、企业白领、创业…）</td></tr><tr><td><strong>marriage</strong></td><td>婚姻状态（未婚、已婚、离异、丧偶）</td></tr><tr><td><strong>offsprings</strong></td><td>子女状态(无子女、学前、小学、中学、大学、工作)</td></tr><tr><td><strong>house_loan_status</strong></td><td>房屋贷款状况（无房贷、正在还房贷、已经还完房贷）</td></tr></tbody></table></div><ul><li>选手提交 submission.csv</li></ul><div class="table-container"><table><thead><tr><th>字段名</th><th>字段说明</th></tr></thead><tbody><tr><td>id</td><td>贷款记录ID</td></tr><tr><td>isDefault</td><td>是否违约（可为概率、最后我们提交的是归一化rank)</td></tr></tbody></table></div><h3 id="数据探索"><a href="#数据探索" class="headerlink" title="数据探索"></a>数据探索</h3><ul><li>少量的缺失值，最多缺失的特征列也不到10%</li><li><p>大量的特征格式问题</p></li><li><p>主表train_public缺失工资、有无子女等重要相关特征</p></li></ul>]]></content>
    
    
    <categories>
      
      <category>数据科学</category>
      
      <category>比赛</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
      <tag>迁移学习</tag>
      
      <tag>金融</tag>
      
      <tag>风控</tag>
      
      <tag>DataFountain</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【比赛】Kaggle - G-Research Crypto Forecasting</title>
    <link href="/2021/12/02/%E3%80%90%E6%AF%94%E8%B5%9B%E3%80%91Kaggle%20-%20G-Research%20Crypto%20Forecasting/"/>
    <url>/2021/12/02/%E3%80%90%E6%AF%94%E8%B5%9B%E3%80%91Kaggle%20-%20G-Research%20Crypto%20Forecasting/</url>
    
    <content type="html"><![CDATA[<h2 id="前期分析"><a href="#前期分析" class="headerlink" title="前期分析"></a>前期分析</h2><h3 id="需求分析"><a href="#需求分析" class="headerlink" title="需求分析"></a>需求分析</h3><p>简述：预测14款比特币未来的趋势，七七八八弄了一个较为复杂的Target，内核就是预测趋势，准确来说，是未来加密货币的随着时间的价格变化率的近似，而评估指标是加权的皮尔逊相关系数。</p><div class="note note-success">            <p><a href="https://www.kaggle.com/c/g-research-crypto-forecasting/overview/description">G-Research Crypto Forecasting | Kaggle</a></p>          </div><h3 id="Dataset-Structure"><a href="#Dataset-Structure" class="headerlink" title="Dataset Structure"></a>Dataset Structure</h3><p> <strong>train.csv</strong> - The training set</p><ol><li>timestamp - A timestamp for the minute covered by the row.</li><li>Asset_ID - An ID code for the cryptoasset (加密资产).</li><li>Count - The number of trades that took place this minute. 一分钟发生的交易数量。</li><li>Open - The USD price at the beginning of the minute. 起始价</li><li>High - The highest USD price during the minute. 最高价</li><li>Low - The lowest USD price during the minute. 最低价</li><li>Close - The USD price at the end of the minute. 结束价</li><li>Volume - The number of cryptoasset u units traded during the minute. 分钟总交易额</li><li>VWAP - The volume-weighted average price for the minute. </li><li>Target - 15 minute residualized returns. See the ‘Prediction and Evaluation section of this notebook for details of how the target is calculated.</li><li>Weight - Weight, defined by the competition hosts <a href="https://www.kaggle.com/cstein06/tutorial-to-the-g-research-crypto-competition">here</a></li><li>Asset_Name - Human readable Asset name.</li></ol><p><strong>example_test.csv</strong> - An example of the data that will be delivered by the time series API.</p><p><strong>example_sample_submission.csv</strong> - An example of the data that will be delivered by the time series API. The data is just copied from train.csv.</p><p><strong>asset_details.csv</strong> - Provides the real name and of the cryptoasset for each Asset_ID and the weight each cryptoasset receives in the metric.</p><p><strong>supplemental_train.csv</strong> - After the submission period is over this file’s data will be replaced with cryptoasset prices from the submission period. In the Evaluation phase, the train, train supplement, and test set will be contiguous in time, apart from any missing data. The current copy, which is just filled approximately the right amount of data from train.csv is provided as a placeholder.</p><ul><li>📌 There are 14 coins in the dataset</li><li>📌 There are 4 years in the [full] dataset</li></ul><h3 id="Baseline"><a href="#Baseline" class="headerlink" title="Baseline"></a>Baseline</h3><ul><li><a href="https://www.kaggle.com/c/g-research-crypto-forecasting/discussion/290806">G-Research Crypto Forecasting | Kaggle</a> ——GrandMaster分享。</li><li><a href="https://cloud.tencent.com/developer/article/1120107">教程 | Kaggle网站流量预测任务第一名解决方案：从模型到代码详解时序预测 - 云+社区 - 腾讯云 (tencent.com)</a></li><li><a href="https://www.kaggle.com/yamqwe/g-research-avoid-overfit-feature-neutralization/">[G-Research] Avoid Overfit: Feature Neutralization | Kaggle</a> ——防止过拟合</li><li><a href="https://www.kaggle.com/c/g-research-crypto-forecasting/discussion/284903">G-Research Crypto Forecasting | Kaggle</a> ——相关案例分享</li><li><a href="https://www.kaggle.com/alexfir/recreating-target">Recreating Target | Kaggle</a> —— 重建label</li></ul><h3 id="Competetion-Target"><a href="#Competetion-Target" class="headerlink" title="Competetion Target"></a>Competetion Target</h3><ul><li><p>监督学习，所需要预测目标——“Target”特征</p><ul><li><strong>Target</strong>: Residual log-returns for the asset over a 15 minute horizon.</li></ul><p><img src="/2021/12/02/%E3%80%90%E6%AF%94%E8%B5%9B%E3%80%91Kaggle%20-%20G-Research%20Crypto%20Forecasting/image-20211202000637295.png" alt="Target"></p></li></ul><div class="note note-success">            <blockquote><p>图片来源：<a href="https://www.kaggle.com/cstein06/tutorial-to-the-g-research-crypto-competition">G-Research 加密竞赛教程 |卡格尔 (kaggle.com)</a></p></blockquote>          </div><ul><li>评价指标：<span class="label label-primary">Target的加权皮尔逊相关系数</span> </li></ul><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">weighted_correlation</span>(<span class="hljs-params">a, b, weights</span>):</span><br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">   a:预测值</span><br><span class="hljs-string">   b:实际值</span><br><span class="hljs-string">   weights:Asset权重</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br>    w = np.ravel(weights)<br>    a = np.ravel(a)<br>    b = np.ravel(b)<br><br>    sum_w = np.<span class="hljs-built_in">sum</span>(w)<br>    mean_a = np.<span class="hljs-built_in">sum</span>(a * w) / sum_w<br>    mean_b = np.<span class="hljs-built_in">sum</span>(b * w) / sum_w<br>    var_a = np.<span class="hljs-built_in">sum</span>(w * np.square(a - mean_a)) / sum_w<br>    var_b = np.<span class="hljs-built_in">sum</span>(w * np.square(b - mean_b)) / sum_w<br><br>    cov = np.<span class="hljs-built_in">sum</span>((a * b * w)) / np.<span class="hljs-built_in">sum</span>(w) - mean_a * mean_b<br>    corr = cov / np.sqrt(var_a * var_b)<br><br>    <span class="hljs-keyword">return</span> corr<br></code></pre></div></td></tr></table></figure><ul><li>进一步分析，该分数重点可拆分为两点：<ol><li><strong>权重</strong>，由于是加权皮尔逊相关系数，那么权重更大的Target对相关系数的贡献越多</li><li><strong>相关系数</strong>，也即比较的是相关性，是变化率之间的联系，相当于是时序之中的斜率，也即在未来时间段看涨还是看跌。</li></ol></li></ul><h2 id="数据观测"><a href="#数据观测" class="headerlink" title="数据观测"></a>数据观测</h2>]]></content>
    
    
    <categories>
      
      <category>数据科学</category>
      
      <category>比赛</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
      <tag>金融</tag>
      
      <tag>时序分析</tag>
      
      <tag>Kaggle</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【Data Science】决策树家族史</title>
    <link href="/2021/12/01/%E3%80%90Data%20Science%E3%80%91%E5%86%B3%E7%AD%96%E6%A0%91%E5%AE%B6%E6%97%8F%E5%8F%B2/"/>
    <url>/2021/12/01/%E3%80%90Data%20Science%E3%80%91%E5%86%B3%E7%AD%96%E6%A0%91%E5%AE%B6%E6%97%8F%E5%8F%B2/</url>
    
    <content type="html"><![CDATA[<h2 id="决策树基础"><a href="#决策树基础" class="headerlink" title="决策树基础"></a>决策树基础</h2><h3 id="贪心决策树的案底"><a href="#贪心决策树的案底" class="headerlink" title="贪心决策树的案底"></a>贪心决策树的案底</h3><ul><li><p>最基础的弱学习器——决策树，其贪心雅号来源于他的优化算法——<strong>贪心算法</strong>，也即每一步特征切分都是<strong>局部最优，而非全局最优。</strong>大抵就是只顾当前，不顾未来，之后咋样，我管不着的算法。</p></li><li><p>一些聊胜于无的专业术语：叶节点、根结点、内部结点。</p><p><img src="/2021/12/01/%E3%80%90Data%20Science%E3%80%91%E5%86%B3%E7%AD%96%E6%A0%91%E5%AE%B6%E6%97%8F%E5%8F%B2/%E7%88%B1%E8%AE%B0%E4%B8%8D%E8%AE%B0%E7%B3%BB%E5%88%97-16383607496321.png" alt="决策树构架"></p></li><li><p>贪心的决策树算法分为三个部分——如何切分（切分特征与切分点的选择）、决策树的生成、决策树的剪枝。</p></li></ul><h3 id="决策树切分"><a href="#决策树切分" class="headerlink" title="决策树切分"></a>决策树切分</h3><p>首先我们先从分类问题进行切入，回归问题将循序渐进的介绍，因为决策树最开始是专职处理分类问题，后随着要求的不断更迭，决策树算法也可以处理连续型与混合型。</p><h4 id="不纯度"><a href="#不纯度" class="headerlink" title="不纯度"></a>不纯度</h4><ul><li><p>我们希望决策树的分支结点所包含的样本尽可能属于同⼀类别，即结点的 “纯度”（purity）越来越⾼。在分类树中，划分的优劣⽤不纯度度量（impurity-measure）定量分析。</p><blockquote><p>简单来说，不纯度就代表着不确定性，假如按照某种特征与切分点切分后，结果是将label五五分成，这也就代表了最混乱的状态，这类切分毫无意义，我奶奶来切都比他切得好。</p></blockquote></li><li><p>分别为<em>Entropy</em>（熵）、<em>Gini index</em>（基尼系数）、<em>Classification error</em>（误分类误差）。以下的p均代表label占总体的比例，$p_1$代表第一类label的占比。</p></li><li><p>Entropy</p><script type="math/tex; mode=display">  Entropy(p) = -\sum_{i=1}p_i*\log_2p_i</script><blockquote><p>当切分的子节点为2个时，易得该项为Cross-Entropy</p></blockquote></li><li><p>Gini index</p><script type="math/tex; mode=display">  Gini(p) = 1 -\sum_{i=1}p^2_i</script></li><li><p>Classification Error</p><script type="math/tex; mode=display">CE(p) = 1-\max(p)</script></li></ul><p><img src="/2021/12/01/%E3%80%90Data%20Science%E3%80%91%E5%86%B3%E7%AD%96%E6%A0%91%E5%AE%B6%E6%97%8F%E5%8F%B2/Geogebra%E4%B9%B1%E7%94%BB%E7%B3%BB%E5%88%97-16383608315661.png" alt="不纯度"></p><ul><li>决策树最终的优化⽬标是<strong>让叶结点的总不纯度最低</strong>，即对应衡量不纯度的指标最低(但实际上贪心算法是短视的,它只能保证每一步的总不纯度是最小的,无法倒退)</li></ul><h4 id="信息增益"><a href="#信息增益" class="headerlink" title="信息增益"></a>信息增益</h4><ul><li><p>通常我们说的信息增益，是默认<em>信息熵</em>作为不纯度的度量。</p></li><li><p>定义信息增益为Gain, 父结点不纯度impurity为I(parent),子结点的总不纯度为I(child)，故：</p></li></ul><script type="math/tex; mode=display">Gain = I(parent) - I(child)</script><ul><li><p>由于I(parent)是既定的，故要使得Gain最大，实际上是需要I(child)最小，对于I(child)，其实际为条件不纯度的加权平均综合。</p></li><li><p>若以熵为例，则其等价于条件熵——$H(Y|X)$代表<em>条件熵</em>，$H(Y|X=x)$代表后验熵（注意负号），<strong>信息增益优化的目标就是让条件熵最小</strong>。</p><script type="math/tex; mode=display">H(Y|X) = \sum_{x\in X}p(x)H(Y|X=x)\\\\H(Y|X=x) = -\sum_{y\in Y}p(y|x)*\log_2{p(y|x)}</script></li></ul><h3 id="决策树生成（三大决策树算法）"><a href="#决策树生成（三大决策树算法）" class="headerlink" title="决策树生成（三大决策树算法）"></a>决策树生成（三大决策树算法）</h3><h4 id="算法明灯——ID3算法"><a href="#算法明灯——ID3算法" class="headerlink" title="算法明灯——ID3算法"></a>算法明灯——ID3算法</h4><ul><li>撒旦来了都说好的ID3算法原型来源于 J.R Quinlan 的博士论⽂，是早期基础理论较为完善，使用较为⼴泛的决策树模型，在此基础上 J.R Quinlan 进行优化后，陆续推出了C4.5 和 C5.0 决策树算法。</li><li><p>ID3算法的核心是在决策树各个结点应⽤<strong>信息增益</strong>准则选择特征，递归地构建决策树。具体⽅法是： </p><ol><li><p>从根结点开始，对结点计算所有可能的特征的信息增益。</p></li><li><p><strong>选择信息增益最大的特征</strong>作为切分结点的特征。</p></li><li>由该特征的不同取值建立子结点 再对每个子结点也递归的使用如根节点同样的处理方式。</li><li>直到所有特征的信息增益都小于设定的阈值（再切分的收益很小了）或没有特征可以选择为止（信息增益已经没有压榨空间了），最后得到一颗决策树。</li></ol></li><li><p>ID3算法的优缺点：</p><ul><li><p>Advantages: 开创性，他的到来为后来的各种进阶算法打下了基础。</p></li><li><p>Disadvantages（包揽了能想到的所有缺点）:</p><ul><li><strong>不能处理连续型数据。</strong></li><li><p>信息熵为基础的信息增益，如同一个鼓动多分类的罪犯，<strong>他的滔天大罪就是倡导毫无必要的多分类</strong>。因为分类个数越多，信息增益就会变高，于是乎讨喜的特征总会是那些让人直呼上帝的多分类特征。极端条件下，每个样本对应一个分类的特征占据了信息增益最大化的最优解，而这不是我们想看到的。</p></li><li><p><strong>无法很好的处理缺失值。</strong></p></li><li>没有任何的剪枝处理，<strong>严重过拟合。</strong></li></ul></li></ul></li><li>ID3如此之多的缺点，堪称经典负面教材，它赤裸裸的展示了其堪称完美的体无完肤，为后来的C4.5、C5.0等算法开创了鲜明的道路，值得谬赞。</li></ul><div class="note note-success">            <p>附一个ID3的代码（仅供参考）：</p>          </div><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs Python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">calEnt</span>(<span class="hljs-params">dataSet</span>):</span><br>    n = dataSet.shape[<span class="hljs-number">0</span>] <span class="hljs-comment"># 数据集总⾏数</span><br>    iset = dataSet.iloc[:,-<span class="hljs-number">1</span>].value_counts() <span class="hljs-comment"># 标签的所有类别</span><br>    p = iset/n <span class="hljs-comment"># 每⼀类标签所占⽐</span><br>    ent = (-p*np.log2(p)).<span class="hljs-built_in">sum</span>() <span class="hljs-comment"># 计算信息熵</span><br>    <span class="hljs-keyword">return</span> ent<br><br><span class="hljs-comment"># 创建数据集</span><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">createDataSet</span>():</span><br>    row_data = &#123;<span class="hljs-string">&#x27;accompany&#x27;</span>:[<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>],<br>                <span class="hljs-string">&#x27;game&#x27;</span>:[<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>],<br>                <span class="hljs-string">&#x27;bad boy&#x27;</span>:[<span class="hljs-string">&#x27;yes&#x27;</span>,<span class="hljs-string">&#x27;yes&#x27;</span>,<span class="hljs-string">&#x27;no&#x27;</span>,<span class="hljs-string">&#x27;no&#x27;</span>,<span class="hljs-string">&#x27;no&#x27;</span>]&#125;<br>    dataSet = pd.DataFrame(row_data)<br>    <span class="hljs-keyword">return</span> dataSet<br>dataSet = createDataSet()<br><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">参数说明：</span><br><span class="hljs-string"> dataSet：原始数据集</span><br><span class="hljs-string">返回：</span><br><span class="hljs-string"> axis：数据集最佳切分列的索引</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br><span class="hljs-comment"># 选择最优的列进⾏切分</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">bestSplit</span>(<span class="hljs-params">dataSet</span>):</span><br>    baseEnt = calEnt(dataSet) <span class="hljs-comment"># 计算原始熵</span><br>    bestGain = <span class="hljs-number">0</span> <span class="hljs-comment"># 初始化信息增益</span><br>    axis = -<span class="hljs-number">1</span> <span class="hljs-comment"># 初始化最佳切分列，</span><br>标签列<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(dataSet.shape[<span class="hljs-number">1</span>]-<span class="hljs-number">1</span>): <span class="hljs-comment"># 对特征的每⼀列进⾏</span><br>    循环<br>    levels= dataSet.iloc[:,i].value_counts().index <span class="hljs-comment"># 提取出当前列的所有</span><br>    取值<br>    ents = <span class="hljs-number">0</span> <span class="hljs-comment"># 初始化⼦节点的信息</span><br>    熵<br>    <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> levels: <span class="hljs-comment"># 对当前列的每⼀个取值进⾏循环</span><br>        childSet = dataSet[dataSet.iloc[:,i]==j] <span class="hljs-comment"># 某⼀个⼦节点的dataframe</span><br>        ent = calEnt(childSet) <span class="hljs-comment"># 计算某⼀个⼦节点的信息熵</span><br>        ents += (childSet.shape[<span class="hljs-number">0</span>]/dataSet.shape[<span class="hljs-number">0</span>])*ent <span class="hljs-comment"># 计算当前列的信息熵</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;第<span class="hljs-subst">&#123;i&#125;</span>列的信息熵为<span class="hljs-subst">&#123;ents&#125;</span>&#x27;</span>)<br>        infoGain = baseEnt-ents <span class="hljs-comment"># 计算当前列的信息增益</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;第<span class="hljs-subst">&#123;i&#125;</span>列的信息增益为<span class="hljs-subst">&#123;infoGain&#125;</span>&#x27;</span>)<br>        <span class="hljs-keyword">if</span> (infoGain &gt; bestGain):<br>            bestGain = infoGain <span class="hljs-comment"># 选择最⼤信息增益</span><br>            axis = i <span class="hljs-comment"># 最⼤信息增益所在列</span><br>            的索引<br>            <span class="hljs-keyword">return</span> axis<br>        <br><span class="hljs-comment"># bestSplit(dataSet) # 返回的结果为0，即选择第0列来切分数据集</span><br><br><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">函数功能：按照给定的列划分数据集</span><br><span class="hljs-string">参数说明：</span><br><span class="hljs-string"> dataSet：原始数据集</span><br><span class="hljs-string"> axis：指定的列索引</span><br><span class="hljs-string"> value：指定的属性值</span><br><span class="hljs-string">返回：</span><br><span class="hljs-string"> redataSet：按照指定列索引和属性值切分后的数据集</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">mySplit</span>(<span class="hljs-params">dataSet,axis,value</span>):</span><br>    col = dataSet.columns[axis]<br>    redataSet = dataSet.loc[dataSet[col]==value,:].drop(col,axis=<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">return</span> redataSet<br><br><br><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">函数功能：基于最⼤信息增益切分数据集，递归构建决策树</span><br><span class="hljs-string">参数说明：</span><br><span class="hljs-string"> dataSet：原始数据集(最有⼀列是标签)</span><br><span class="hljs-string">返回：</span><br><span class="hljs-string"> myTree：字典形式的树</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">createTree</span>(<span class="hljs-params">dataSet</span>):</span><br>    featlist = <span class="hljs-built_in">list</span>(dataSet.columns) <span class="hljs-comment"># 提取出数据集所有的列</span><br>    classlist = dataSet.iloc[:,-<span class="hljs-number">1</span>].value_counts() <span class="hljs-comment"># 获取最后⼀列类标签</span><br>    <span class="hljs-comment"># 判断最多标签数⽬是否等于数据集⾏数，或者数据集是否只有⼀列</span><br>    <span class="hljs-keyword">if</span> classlist[<span class="hljs-number">0</span>]==dataSet.shape[<span class="hljs-number">0</span>] <span class="hljs-keyword">or</span> dataSet.shape[<span class="hljs-number">1</span>] == <span class="hljs-number">1</span>:<br>        <span class="hljs-keyword">return</span> classlist.index[<span class="hljs-number">0</span>] <span class="hljs-comment"># 如果是，返回类标签</span><br>    axis = bestSplit(dataSet) <span class="hljs-comment"># 确定出当前最佳切分列的索引</span><br>    bestfeat = featlist[axis] <span class="hljs-comment"># 获取该索引对应的特征</span><br>    myTree = &#123;bestfeat:&#123;&#125;&#125; <span class="hljs-comment"># 采⽤字典嵌套的⽅式存储树信息</span><br>    <span class="hljs-keyword">del</span> featlist[axis] <span class="hljs-comment"># 删除当前特征</span><br>    valuelist = <span class="hljs-built_in">set</span>(dataSet.iloc[:,axis]) <span class="hljs-comment"># 提取最佳切分列所有属性值</span><br>    <span class="hljs-keyword">for</span> value <span class="hljs-keyword">in</span> valuelist: <span class="hljs-comment"># 对每⼀个属性值递归建</span><br>        树<br>        myTree[bestfeat][value] = createTree(mySplit(dataSet,axis,value))<br>        <span class="hljs-keyword">return</span> myTree<br>    <br>myTree = createTree(dataSet)<br>myTree<br><br></code></pre></div></td></tr></table></figure><h4 id="C4-5算法"><a href="#C4-5算法" class="headerlink" title="C4.5算法"></a>C4.5算法</h4><ul><li>C4.5算法最主要的改变是将ID3算法中的以信息增益作为划分节点的依据，改为了以<strong>信息增益比</strong>作为优化对象。</li></ul>]]></content>
    
    
    <categories>
      
      <category>数据科学</category>
      
      <category>模型选择</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
      <tag>决策树</tag>
      
      <tag>集成学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【Data Science】Python机器学习实用库（一）</title>
    <link href="/2021/11/02/%E3%80%90Data%20Science%E3%80%91Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E7%94%A8%E5%BA%93%EF%BC%88%E4%B8%80%EF%BC%89/"/>
    <url>/2021/11/02/%E3%80%90Data%20Science%E3%80%91Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E7%94%A8%E5%BA%93%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<div class="table-container"><table><thead><tr><th>库名</th><th>功能</th></tr></thead><tbody><tr><td>Numpy(SciPy) / Pandas / Matplotlib</td><td>三剑客，统计基础</td></tr><tr><td>Sklearn / Statsmodels / Eli5</td><td>结构化ML常用框架</td></tr><tr><td>Tqdm / Re / Gc / Os / Warning / Time</td><td>常用的基础辅助库</td></tr><tr><td>Imbalanced-learn / Missingpy</td><td>特征工程常用库</td></tr><tr><td>Seaborn / Pyecharts / Plotly</td><td>可视化常用库</td></tr><tr><td>Pandas_profiling</td><td>数据分析看板库</td></tr><tr><td>Optuna / Scikit-optimize / Skopt / HyperOpt</td><td>贝叶斯优化库</td></tr><tr><td>Pytorch / Tersonflow / Keras / Theano / Sonnet</td><td>DL常用框架</td></tr><tr><td>Xgboost / Catboost / Lightgbm / Ngboost</td><td>四大集成树模型</td></tr><tr><td>PyFlux</td><td>时序模型</td></tr><tr><td>Pycaret / MLJAR AutoML</td><td>AutoML库</td></tr><tr><td>Featuretools</td><td>特征构造库</td></tr><tr><td>Faker</td><td>假数据生成</td></tr><tr><td>Scrapy</td><td>数据采集</td></tr></tbody></table></div>]]></content>
    
    
    <categories>
      
      <category>数据科学</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
      <tag>库</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【Data Science】常用统计指标</title>
    <link href="/2021/10/09/%E3%80%90Data%20Science%E3%80%91%E5%B8%B8%E7%94%A8%E7%BB%9F%E8%AE%A1%E6%8C%87%E6%A0%87/"/>
    <url>/2021/10/09/%E3%80%90Data%20Science%E3%80%91%E5%B8%B8%E7%94%A8%E7%BB%9F%E8%AE%A1%E6%8C%87%E6%A0%87/</url>
    
    <content type="html"><![CDATA[<h2 id="基础指标"><a href="#基础指标" class="headerlink" title="基础指标"></a>基础指标</h2><h3 id="平均数"><a href="#平均数" class="headerlink" title="平均数"></a>平均数</h3><ul><li><p>任一数据的变动都会引起该数值的变动，<strong>受极端值影响较大</strong>。</p></li><li><p>通常而言我们不会使用平均数来填充缺失值。</p><ul><li>均值会因偏态而无法准确反应样本实际情况，使用要慎重。</li></ul></li></ul><ul><li>平均数需要有实际意义，注意辛普森悖论。</li></ul><h3 id="众数"><a href="#众数" class="headerlink" title="众数"></a>众数</h3><ul><li><p>分类问题中常用，偷懒时，可用于离散型缺失值填充。</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">series.fillna(series.mode()[<span class="hljs-number">0</span>],inplace = <span class="hljs-literal">True</span>)<br></code></pre></div></td></tr></table></figure></li><li><p>众数也即频数，频数通常在特征构造中时常使用，作为一种特殊的编码(Frequence Encoder）。</p></li></ul><h3 id="百分位数"><a href="#百分位数" class="headerlink" title="百分位数"></a>百分位数</h3><ul><li><p>中位数：连续问题中常用此来观测数据的偏态，且可用于<strong>对完全随机缺失的连续性特征进行填充</strong>。</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">series.fillna(series.median().inplace = <span class="hljs-literal">True</span>)<br></code></pre></div></td></tr></table></figure></li><li><p>其他百分位数</p><ul><li>分箱</li><li>异常值阈值</li></ul></li></ul><h3 id="相对数"><a href="#相对数" class="headerlink" title="相对数"></a>相对数</h3><ul><li>增量</li><li>比率</li></ul><h2 id="泛化误差"><a href="#泛化误差" class="headerlink" title="泛化误差"></a>泛化误差</h2><h3 id="数学期望"><a href="#数学期望" class="headerlink" title="数学期望"></a>数学期望</h3><h3 id="方差-Var"><a href="#方差-Var" class="headerlink" title="方差(Var)"></a>方差(Var)</h3><h3 id="标准差-Std"><a href="#标准差-Std" class="headerlink" title="标准差(Std)"></a>标准差(Std)</h3><h3 id="协方差-Cov"><a href="#协方差-Cov" class="headerlink" title="协方差(Cov)"></a>协方差(Cov)</h3><h3 id="相关系数-Corr"><a href="#相关系数-Corr" class="headerlink" title="相关系数(Corr)"></a>相关系数(Corr)</h3><h3 id="可决系数-R-2"><a href="#可决系数-R-2" class="headerlink" title="可决系数(R^2)"></a>可决系数(R^2)</h3><h3 id="离差平方和-SST"><a href="#离差平方和-SST" class="headerlink" title="离差平方和(SST)"></a>离差平方和(SST)</h3><h3 id="残差-组间-平方和-SSE"><a href="#残差-组间-平方和-SSE" class="headerlink" title="残差(组间)平方和(SSE)"></a>残差(组间)平方和(SSE)</h3><h3 id="回归-组内-平方和-SSR"><a href="#回归-组内-平方和-SSR" class="headerlink" title="回归(组内)平方和(SSR)"></a>回归(组内)平方和(SSR)</h3><h3 id="泛化误差三大组成——噪音-偏差-方差"><a href="#泛化误差三大组成——噪音-偏差-方差" class="headerlink" title="泛化误差三大组成——噪音\偏差\方差"></a>泛化误差三大组成——噪音\偏差\方差</h3><h2 id="分类问题——混淆矩阵（二分类为基础）"><a href="#分类问题——混淆矩阵（二分类为基础）" class="headerlink" title="分类问题——混淆矩阵（二分类为基础）"></a>分类问题——混淆矩阵（二分类为基础）</h2><h3 id="TP、FP、TN、FN"><a href="#TP、FP、TN、FN" class="headerlink" title="TP、FP、TN、FN"></a>TP、FP、TN、FN</h3><h3 id="TPR、FPR、TNR、FNR"><a href="#TPR、FPR、TNR、FNR" class="headerlink" title="TPR、FPR、TNR、FNR"></a>TPR、FPR、TNR、FNR</h3><h3 id="第一类错误、第二类错误、Accuracy、Precision、Recall"><a href="#第一类错误、第二类错误、Accuracy、Precision、Recall" class="headerlink" title="第一类错误、第二类错误、Accuracy、Precision、Recall"></a>第一类错误、第二类错误、Accuracy、Precision、Recall</h3><h3 id="f1-score、fn-score"><a href="#f1-score、fn-score" class="headerlink" title="f1-score、fn-score"></a>f1-score、fn-score</h3><h3 id="AUC"><a href="#AUC" class="headerlink" title="AUC"></a>AUC</h3><h2 id="回归问题"><a href="#回归问题" class="headerlink" title="回归问题"></a>回归问题</h2><h3 id="MSE"><a href="#MSE" class="headerlink" title="MSE"></a>MSE</h3><h3 id="RMSE"><a href="#RMSE" class="headerlink" title="RMSE"></a>RMSE</h3><h2 id="数据分布"><a href="#数据分布" class="headerlink" title="数据分布"></a>数据分布</h2><h3 id="显著性、置信度、置信区间"><a href="#显著性、置信度、置信区间" class="headerlink" title="显著性、置信度、置信区间"></a>显著性、置信度、置信区间</h3><h3 id="F、t、N、卡方检验值"><a href="#F、t、N、卡方检验值" class="headerlink" title="F、t、N、卡方检验值"></a>F、t、N、卡方检验值</h3><h3 id="熵、交叉熵、KL散度"><a href="#熵、交叉熵、KL散度" class="headerlink" title="熵、交叉熵、KL散度"></a>熵、交叉熵、KL散度</h3><h3 id="极大似然估计量与最大后验估计量"><a href="#极大似然估计量与最大后验估计量" class="headerlink" title="极大似然估计量与最大后验估计量"></a>极大似然估计量与最大后验估计量</h3>]]></content>
    
    
    <categories>
      
      <category>数据科学</category>
      
    </categories>
    
    
    <tags>
      
      <tag>评价指标</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
